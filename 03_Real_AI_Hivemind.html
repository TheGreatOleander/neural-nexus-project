<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real AI Hive-Mind Integration</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Courier New', monospace;
            background: linear-gradient(45deg, #0a0a0a, #1a1a2e, #16213e);
            color: #00ff88;
            overflow-x: hidden;
            overflow-y: auto;
            min-height: 100vh;
            -webkit-overflow-scrolling: touch;
        }

        .container {
            display: flex;
            flex-direction: column;
            min-height: 100vh;
            padding: 20px;
            gap: 20px;
        }

        .header {
            text-align: center;
            padding: 20px;
            background: rgba(0, 0, 0, 0.8);
            border: 2px solid #00ff88;
            border-radius: 10px;
        }

        .title {
            font-size: 2em;
            color: #ffaa00;
            text-shadow: 0 0 20px #ffaa00;
            margin-bottom: 10px;
        }

        .subtitle {
            font-size: 1em;
            color: #00ff88;
            opacity: 0.8;
        }

        .panel {
            background: rgba(0, 0, 0, 0.7);
            border: 2px solid #00ff88;
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 0 20px rgba(0, 255, 136, 0.3);
        }

        .panel h3 {
            color: #ffaa00;
            margin-bottom: 15px;
            font-size: 1.3em;
        }

        .config-section {
            margin-bottom: 30px;
        }

        .input-group {
            margin-bottom: 15px;
        }

        .input-group label {
            display: block;
            margin-bottom: 5px;
            color: #00ff88;
            font-weight: bold;
        }

        .input-group input, .input-group select, .input-group textarea {
            width: 100%;
            padding: 10px;
            background: rgba(0, 0, 0, 0.7);
            border: 1px solid #00ff88;
            border-radius: 5px;
            color: #00ff88;
            font-family: 'Courier New', monospace;
        }

        .input-group textarea {
            height: 100px;
            resize: vertical;
        }

        .btn {
            padding: 12px 20px;
            background: rgba(0, 0, 0, 0.8);
            border: 2px solid #00ff88;
            color: #00ff88;
            border-radius: 8px;
            cursor: pointer;
            font-family: inherit;
            font-size: 1em;
            transition: all 0.3s ease;
            margin-right: 10px;
            margin-bottom: 10px;
        }

        .btn:hover {
            background: rgba(0, 255, 136, 0.1);
            box-shadow: 0 0 15px rgba(0, 255, 136, 0.5);
        }

        .btn.primary {
            background: rgba(255, 170, 0, 0.2);
            border-color: #ffaa00;
            color: #ffaa00;
        }

        .btn.danger {
            background: rgba(255, 107, 107, 0.2);
            border-color: #ff6b6b;
            color: #ff6b6b;
        }

        .status-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin-bottom: 20px;
        }

        .status-card {
            background: rgba(0, 0, 0, 0.8);
            border: 1px solid #00ff88;
            border-radius: 8px;
            padding: 15px;
            text-align: center;
        }

        .status-card.connected {
            border-color: #00ff88;
            box-shadow: 0 0 10px rgba(0, 255, 136, 0.3);
        }

        .status-card.disconnected {
            border-color: #ff6b6b;
            opacity: 0.6;
        }

        .status-card.processing {
            border-color: #ffaa00;
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.02); }
        }

        .model-name {
            font-size: 1.2em;
            color: #ffaa00;
            margin-bottom: 10px;
        }

        .model-status {
            font-size: 0.9em;
            margin-bottom: 10px;
        }

        .model-stats {
            font-size: 0.8em;
            color: #888;
        }

        .log-container {
            background: rgba(0, 0, 0, 0.9);
            border: 2px solid #00ff88;
            border-radius: 10px;
            padding: 15px;
            height: 400px;
            overflow-y: auto;
            -webkit-overflow-scrolling: touch;
        }

        .log-entry {
            margin-bottom: 8px;
            padding: 5px;
            border-left: 3px solid #00ff88;
            padding-left: 10px;
        }

        .log-entry.error {
            border-left-color: #ff6b6b;
            color: #ff6b6b;
        }

        .log-entry.warning {
            border-left-color: #ffaa00;
            color: #ffaa00;
        }

        .log-entry.success {
            border-left-color: #00ff88;
            color: #00ff88;
        }

        .collective-response {
            background: rgba(0, 0, 0, 0.9);
            border: 2px solid #ffaa00;
            border-radius: 10px;
            padding: 20px;
            margin-top: 20px;
            min-height: 200px;
        }

        .response-header {
            color: #ffaa00;
            font-size: 1.2em;
            margin-bottom: 15px;
            text-align: center;
        }

        .individual-response {
            background: rgba(0, 0, 0, 0.5);
            border: 1px solid #00ff88;
            border-radius: 5px;
            padding: 10px;
            margin-bottom: 10px;
        }

        .response-model {
            color: #ffaa00;
            font-weight: bold;
            margin-bottom: 5px;
        }

        .code-block {
            background: rgba(0, 0, 0, 0.8);
            border: 1px solid #444;
            border-radius: 5px;
            padding: 15px;
            margin: 10px 0;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            overflow-x: auto;
        }

        .tabs {
            display: flex;
            margin-bottom: 20px;
            flex-wrap: wrap;
        }

        .tab {
            padding: 10px 20px;
            background: rgba(0, 0, 0, 0.7);
            border: 1px solid #444;
            color: #888;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .tab.active {
            background: rgba(0, 255, 136, 0.2);
            border-color: #00ff88;
            color: #00ff88;
        }

        .tab-content {
            display: none;
        }

        .tab-content.active {
            display: block;
        }

        @media (max-width: 768px) {
            .container {
                padding: 10px;
            }
            
            .title {
                font-size: 1.5em;
            }
            
            .status-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <div class="title">REAL AI HIVE-MIND INTEGRATION</div>
            <div class="subtitle">Connect and coordinate multiple local AI models</div>
        </div>

        <div class="tabs">
            <div class="tab active" onclick="switchTab('setup')">Setup</div>
            <div class="tab" onclick="switchTab('monitor')">Monitor</div>
            <div class="tab" onclick="switchTab('collective')">Collective Intelligence</div>
            <div class="tab" onclick="switchTab('instructions')">Instructions</div>
        </div>

        <div id="setup" class="tab-content active">
            <div class="panel">
                <h3>AI Model Configuration</h3>
                
                <div class="config-section">
                    <div class="input-group">
                        <label>Model Name:</label>
                        <input type="text" id="modelName" placeholder="e.g., Llama-3.1-8B">
                    </div>
                    
                    <div class="input-group">
                        <label>API Endpoint:</label>
                        <input type="text" id="apiEndpoint" placeholder="http://localhost:1234/v1/chat/completions">
                    </div>
                    
                    <div class="input-group">
                        <label>API Key (if required):</label>
                        <input type="password" id="apiKey" placeholder="Optional">
                    </div>
                    
                    <div class="input-group">
                        <label>Model Type:</label>
                        <select id="modelType">
                            <option value="ollama">Ollama</option>
                            <option value="lmstudio">LM Studio</option>
                            <option value="koboldai">KoboldAI</option>
                            <option value="textgen">Text Generation WebUI</option>
                            <option value="openai">OpenAI Compatible</option>
                            <option value="custom">Custom</option>
                        </select>
                    </div>
                    
                    <button class="btn primary" onclick="addModel()">Add Model</button>
                    <button class="btn" onclick="testConnections()">Test All Connections</button>
                    <button class="btn danger" onclick="clearModels()">Clear All Models</button>
                </div>
            </div>
        </div>

        <div id="monitor" class="tab-content">
            <div class="panel">
                <h3>Connected AI Models</h3>
                <div class="status-grid" id="modelStatusGrid">
                    <!-- Model status cards will be populated here -->
                </div>
                
                <div class="log-container" id="systemLog">
                    <!-- System logs will appear here -->
                </div>
            </div>
        </div>

        <div id="collective" class="tab-content">
            <div class="panel">
                <h3>Collective Intelligence Interface</h3>
                
                <div class="input-group">
                    <label>Query for All Models:</label>
                    <textarea id="collectiveQuery" placeholder="Enter your question or prompt here..."></textarea>
                </div>
                
                <button class="btn primary" onclick="queryAllModels()">Query All Models</button>
                <button class="btn" onclick="synthesizeResponses()">Synthesize Collective Response</button>
                
                <div class="collective-response" id="collectiveResponse">
                    <div class="response-header">Collective AI Response</div>
                    <div id="responseContainer">
                        Submit a query to see responses from all connected models...
                    </div>
                </div>
            </div>
        </div>

        <div id="instructions" class="tab-content">
            <div class="panel">
                <h3>Setup Instructions</h3>
                
                <h4 style="color: #ffaa00; margin: 20px 0 10px 0;">For Ollama:</h4>
                <div class="code-block">
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Pull a model
ollama pull llama3.1:8b

# Start the server (usually runs on localhost:11434)
ollama serve

# Your endpoint: http://localhost:11434/api/chat
                </div>

                <h4 style="color: #ffaa00; margin: 20px 0 10px 0;">For LM Studio:</h4>
                <div class="code-block">
1. Download LM Studio from https://lmstudio.ai/
2. Load a model (e.g., Llama, Mistral, etc.)
3. Start the local server
4. Default endpoint: http://localhost:1234/v1/chat/completions
                </div>

                <h4 style="color: #ffaa00; margin: 20px 0 10px 0;">For Text Generation WebUI:</h4>
                <div class="code-block">
# Clone and setup
git clone https://github.com/oobabooga/text-generation-webui
cd text-generation-webui
./start_linux.sh --api

# Default endpoint: http://localhost:5000/v1/chat/completions
                </div>

                <h4 style="color: #ffaa00; margin: 20px 0 10px 0;">Common Endpoints:</h4>
                <div class="code-block">
Ollama:           http://localhost:11434/api/chat
LM Studio:        http://localhost:1234/v1/chat/completions
KoboldAI:         http://localhost:5001/api/v1/generate
Text-Gen WebUI:   http://localhost:5000/v1/chat/completions
                </div>
            </div>
        </div>
    </div>

    <script>
        class RealAIHiveMind {
            constructor() {
                this.models = JSON.parse(localStorage.getItem('aiModels') || '[]');
                this.responses = {};
                this.init();
            }

            init() {
                this.updateModelStatusGrid();
                this.log('AI Hive-Mind Integration System Initialized', 'success');
                
                // Auto-test connections on startup
                if (this.models.length > 0) {
                    setTimeout(() => this.testConnections(), 1000);
                }
            }

            addModel() {
                const name = document.getElementById('modelName').value;
                const endpoint = document.getElementById('apiEndpoint').value;
                const apiKey = document.getElementById('apiKey').value;
                const type = document.getElementById('modelType').value;

                if (!name || !endpoint) {
                    this.log('Please fill in model name and endpoint', 'error');
                    return;
                }

                const model = {
                    id: Date.now().toString(),
                    name,
                    endpoint,
                    apiKey,
                    type,
                    status: 'disconnected',
                    lastResponse: null,
                    responseTime: 0
                };

                this.models.push(model);
                this.saveModels();
                this.updateModelStatusGrid();
                this.log(`Added model: ${name}`, 'success');

                // Clear form
                document.getElementById('modelName').value = '';
                document.getElementById('apiEndpoint').value = '';
                document.getElementById('apiKey').value = '';
            }

            async testConnections() {
                this.log('Testing connections to all models...', 'warning');
                
                for (let model of this.models) {
                    try {
                        await this.testSingleConnection(model);
                    } catch (error) {
                        this.log(`Connection failed for ${model.name}: ${error.message}`, 'error');
                        model.status = 'disconnected';
                    }
                }
                
                this.updateModelStatusGrid();
                this.saveModels();
            }

            async testSingleConnection(model) {
                const startTime = Date.now();
                model.status = 'connecting';
                this.updateModelStatusGrid();

                try {
                    let response;
                    
                    if (model.type === 'ollama') {
                        response = await this.testOllamaConnection(model);
                    } else {
                        response = await this.testOpenAICompatibleConnection(model);
                    }

                    if (response.ok) {
                        model.status = 'connected';
                        model.responseTime = Date.now() - startTime;
                        this.log(`✓ ${model.name} connected (${model.responseTime}ms)`, 'success');
                    } else {
                        throw new Error(`HTTP ${response.status}`);
                    }
                } catch (error) {
                    model.status = 'disconnected';
                    this.log(`✗ ${model.name} failed: ${error.message}`, 'error');
                }
            }

            async testOllamaConnection(model) {
                return fetch(model.endpoint.replace('/api/chat', '/api/tags'), {
                    method: 'GET',
                    headers: {
                        'Content-Type': 'application/json'
                    }
                });
            }

            async testOpenAICompatibleConnection(model) {
                const headers = {
                    'Content-Type': 'application/json'
                };
                
                if (model.apiKey) {
                    headers['Authorization'] = `Bearer ${model.apiKey}`;
                }

                return fetch(model.endpoint, {
                    method: 'POST',
                    headers,
                    body: JSON.stringify({
                        model: "test",
                        messages: [{"role": "user", "content": "test"}],
                        max_tokens: 1
                    })
                });
            }

            async queryAllModels() {
                const query = document.getElementById('collectiveQuery').value;
                if (!query.trim()) {
                    this.log('Please enter a query', 'error');
                    return;
                }

                const connectedModels = this.models.filter(m => m.status === 'connected');
                if (connectedModels.length === 0) {
                    this.log('No connected models available', 'error');
                    return;
                }

                this.log(`Querying ${connectedModels.length} models...`, 'warning');
                this.responses = {};

                const responseContainer = document.getElementById('responseContainer');
                responseContainer.innerHTML = '<div style="color: #ffaa00;">Processing queries...</div>';

                for (let model of connectedModels) {
                    try {
                        model.status = 'processing';
                        this.updateModelStatusGrid();
                        
                        const response = await this.queryModel(model, query);
                        this.responses[model.id] = {
                            model: model.name,
                            response: response,
                            timestamp: new Date().toLocaleTimeString()
                        };
                        
                        model.status = 'connected';
                        this.log(`✓ Response received from ${model.name}`, 'success');
                    } catch (error) {
                        this.log(`✗ Query failed for ${model.name}: ${error.message}`, 'error');
                        model.status = 'connected'; // Reset status
                    }
                }

                this.updateModelStatusGrid();
                this.displayCollectiveResponse();
            }

            async queryModel(model, query) {
                const headers = {
                    'Content-Type': 'application/json'
                };
                
                if (model.apiKey) {
                    headers['Authorization'] = `Bearer ${model.apiKey}`;
                }

                let body;
                if (model.type === 'ollama') {
                    body = JSON.stringify({
                        model: model.name.toLowerCase(),
                        messages: [{"role": "user", "content": query}],
                        stream: false
                    });
                } else {
                    body = JSON.stringify({
                        model: model.name,
                        messages: [{"role": "user", "content": query}],
                        max_tokens: 500,
                        temperature: 0.7
                    });
                }

                const response = await fetch(model.endpoint, {
                    method: 'POST',
                    headers,
                    body
                });

                if (!response.ok) {
                    throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                }

                const data = await response.json();
                
                if (model.type === 'ollama') {
                    return data.message?.content || 'No response';
                } else {
                    return data.choices?.[0]?.message?.content || 'No response';
                }
            }

            displayCollectiveResponse() {
                const container = document.getElementById('responseContainer');
                let html = '';

                Object.values(this.responses).forEach(resp => {
                    html += `
                        <div class="individual-response">
                            <div class="response-model">${resp.model} (${resp.timestamp})</div>
                            <div>${resp.response}</div>
                        </div>
                    `;
                });

                container.innerHTML = html || '<div style="color: #888;">No responses received</div>';
            }

            synthesizeResponses() {
                const responses = Object.values(this.responses);
                if (responses.length === 0) {
                    this.log('No responses to synthesize', 'error');
                    return;
                }

                // Simple synthesis - in a real implementation, this could use another AI model
                const synthesis = `
                    <div style="background: rgba(255, 170, 0, 0.1); padding: 15px; border-radius: 5px; margin-top: 20px;">
                        <div style="color: #ffaa00; font-weight: bold; margin-bottom: 10px;">SYNTHESIZED COLLECTIVE RESPONSE:</div>
                        <div style="color: #00ff88;">
                            Based on ${responses.length} AI models, the collective insight combines:
                            <ul style="margin: 10px 0; padding-left: 20px;">
                                ${responses.map(r => `<li>${r.model}: ${r.response.substring(0, 100)}...</li>`).join('')}
                            </ul>
                            <strong>Collective Consensus:</strong> The models generally agree on the core concepts while offering complementary perspectives.
                        </div>
                    </div>
                `;

                document.getElementById('responseContainer').innerHTML += synthesis;
                this.log('Collective response synthesized', 'success');
            }

            updateModelStatusGrid() {
                const grid = document.getElementById('modelStatusGrid');
                
                if (this.models.length === 0) {
                    grid.innerHTML = '<div style="color: #888; text-align: center; grid-column: 1/-1;">No models configured</div>';
                    return;
                }

                grid.innerHTML = this.models.map(model => `
                    <div class="status-card ${model.status}">
                        <div class="model-name">${model.name}</div>
                        <div class="model-status">${this.getStatusText(model.status)}</div>
                        <div class="model-stats">
                            Type: ${model.type}<br>
                            ${model.responseTime ? `Response: ${model.responseTime}ms` : ''}
                        </div>
                        <button class="btn" style="margin-top: 10px; font-size: 0.8em;" onclick="hiveMind.removeModel('${model.id}')">Remove</button>
                    </div>
                `).join('');
            }

            getStatusText(status) {
                const statusMap = {
                    'connected': '🟢 Connected',
                    'disconnected': '🔴 Disconnected', 
                    'connecting': '🟡 Connecting...',
                    'processing': '🟠 Processing...'
                };
                return statusMap[status] || status;
            }

            removeModel(id) {
                this.models = this.models.filter(m => m.id !== id);
                this.saveModels();
                this.updateModelStatusGrid();
                this.log('Model removed', 'warning');
            }

            clearModels() {
                if (confirm('Are you sure you want to remove all models?')) {
                    this.models = [];
                    this.saveModels();
                    this.updateModelStatusGrid();
                    this.log('All models cleared', 'warning');
                }
            }

            saveModels() {
                localStorage.setItem('aiModels', JSON.stringify(this.models));
            }

            log(message, type = 'info') {
                const logContainer = document.getElementById('systemLog');
                const timestamp = new Date().toLocaleTimeString();
                const logEntry = document.createElement('div');
                logEntry.className = `log-entry ${type}`;
                logEntry.innerHTML = `<strong>[${timestamp}]</strong> ${message}`;
                
                logContainer.appendChild(logEntry);
                logContainer.scrollTop = logContainer.scrollHeight;

                // Keep only last 100 entries
                while (logContainer.children.length > 100) {
                    logContainer.removeChild(logContainer.firstChild);
                }
            }
        }

        function switchTab(tabName) {
            // Hide all tab contents
            document.querySelectorAll('.tab-content').forEach(content => {
                content.classList.remove('active');
            });
            
            // Remove active class from all tabs
            document.querySelectorAll('.tab').forEach(tab => {
                tab.classList.remove('active');
            });
            
            // Show selected tab content
            document.getElementById(tabName).classList.add('active');
            
            // Add active class to clicked tab
            event.target.classList.add('active');
        }

        // Global functions for onclick handlers
        function addModel() { hiveMind.addModel(); }
        function testConnections() { hiveMind.testConnections(); }
        function clearModels() { hiveMind.clearModels(); }
        function queryAllModels() { hiveMind.queryAllModels(); }
        function synthesizeResponses() { hiveMind.synthesizeResponses(); }

        // Initialize the system
        let hiveMind;
        window.addEventListener('load', () => {
            hiveMind = new RealAIHiveMind();
        });
    </script>

<!-- ETH Donation Footer -->
<div style="margin-top: 40px; padding: 20px; text-align: center; font-family: monospace; font-size: 0.9em; color: #00ffaa;">
    💚 Support this project: <strong>0x0755F4A43C7A567E6554AEedC91F9Fe37737D35F</strong><br>
    <a href="https://etherscan.io/address/0x0755F4A43C7A567E6554AEedC91F9Fe37737D35F" target="_blank" style="color: #ffaa00;">🔗 View Wallet on Etherscan</a><br>
    <span id="eth-balance">Fetching ETH balance...</span>
</div>
<script>
fetch('https://api.etherscan.io/api?module=account&action=balance&address=0x0755F4A43C7A567E6554AEedC91F9Fe37737D35F&tag=latest&apikey=FNBXSBFIN9D3ARRD2DJB4UAP43NKNHFFJH')
    .then(response => response.json())
    .then(function(data) {
        var balanceInEth = parseFloat(data.result) / 1e18;
        document.getElementById('eth-balance').innerText = "Current ETH Support: " + balanceInEth.toFixed(4) + " ETH";
    })
    .catch(function() {
        document.getElementById('eth-balance').innerText = 'Unable to fetch balance';
    });
</script>

</body>
</html>